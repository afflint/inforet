{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive demonstration of boolean retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from corpora.ipynb\n",
      "importing Jupyter notebook from indexing.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "from corpora import FileStream\n",
    "from indexing import Tokenizer, MIndex\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/wikisearch/brat_20'\n",
    "corpus = FileStream(folder, file_ext='txt')\n",
    "tokenizer = Tokenizer(preserve_case=False)\n",
    "Btoken, Blemma = MIndex(), MIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_id in corpus.docs:\n",
    "    doc = corpus.doc(doc_id)\n",
    "    tokens, lemmata = tokenizer.pattern_processing(doc, lemmata=True)\n",
    "    Btoken.boolean(doc_id, tokenizer.remove_punctuation(tokens))\n",
    "    Blemma.boolean(doc_id, tokenizer.remove_punctuation(lemmata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12388 9327\n"
     ]
    }
   ],
   "source": [
    "print len(Btoken), len(Blemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, features, docs = B.boolean_to_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school = m[:,features.index('school')]\n",
    "students = m[:,features.index('students')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.logical_and(school, students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [docs[x] for x in np.where(a)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder + '/queries.json', 'rU') as inj:\n",
    "    queries = json.load(inj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = queries['10']['page_ids']\n",
    "Q = queries['10']['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "government and education\n"
     ]
    }
   ],
   "source": [
    "print Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt, t_features, t_docs = Btoken.boolean_to_matrix()\n",
    "ml, l_features, l_docs = Blemma.boolean_to_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtokens, Qlemma = tokenizer.pattern_processing(Q, lemmata=True)\n",
    "Qt, Ql = tokenizer.remove_punctuation(Qtokens), tokenizer.remove_punctuation(Qlemma)\n",
    "Qt = [x for x in Qt if x != 'and']\n",
    "Ql = [x for x in Qt if x != 'and']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vectors, l_vectors = [], []\n",
    "for token in Qt:\n",
    "    v = mt[:,t_features.index(token)]\n",
    "    t_vectors.append(v)\n",
    "for lemma in Ql:\n",
    "    v = ml[:,l_features.index(lemma)]\n",
    "    l_vectors.append(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjuctive and disjunctive queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vand = vectors[0]\n",
    "for x in vectors[1:]:\n",
    "    vand = np.logical_and(vand, x)\n",
    "vor = vectors[0]\n",
    "for x in vectors[1:]:\n",
    "    vor = np.logical_or(vor, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ra = [docs[x].replace('.txt', '') for x in np.where(vand)[0]]\n",
    "Ro = [docs[x].replace('.txt', '') for x in np.where(vor)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(R, T):\n",
    "    a = float(len([x for x in R if x in T]))\n",
    "    b = float(len(R))\n",
    "    try:\n",
    "        p = a / b\n",
    "    except ZeroDivisionError:\n",
    "        p = np.nan\n",
    "    return p\n",
    "\n",
    "def recall(R, T):\n",
    "    a = float(len([x for x in R if x in T]))\n",
    "    b = float(len(T))\n",
    "    try:\n",
    "        p = a / b\n",
    "    except ZeroDivisionError:\n",
    "        p = np.nan\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print precision(Ra, E), recall(Ra, E), len(Ra), len(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print precision(Ro, E), recall(Ro, E), len(Ro), len(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print Qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens vs lemmata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vort = t_vectors[0]\n",
    "for x in t_vectors[1:]:\n",
    "    vort = np.logical_or(vort, x)\n",
    "vorl = l_vectors[0]\n",
    "for x in l_vectors[1:]:\n",
    "    vorl = np.logical_or(vorl, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rt = [t_docs[x].replace('.txt', '') for x in np.where(vort)[0]]\n",
    "Rl = [l_docs[x].replace('.txt', '') for x in np.where(vorl)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens 0.182795698925 0.85 93 20\n",
      "Lemmata 0.171171171171 0.95 111 20\n"
     ]
    }
   ],
   "source": [
    "print 'Tokens', precision(Rt, E), recall(Rt, E), len(Rt), len(E)\n",
    "print 'Lemmata', precision(Rl, E), recall(Rl, E), len(Rl), len(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
